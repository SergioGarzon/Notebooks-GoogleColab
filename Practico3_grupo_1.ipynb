{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_5lCR5tGmRT"
   },
   "source": [
    "# Práctico 3: Aprendizaje Supervisado\n",
    "\n",
    "## Mentoría *Sesgos Cognitivos en Razonamientos Lógicos*\n",
    "\n",
    "**Fecha de entrega:** 11/09\n",
    "\n",
    "\n",
    "Aplicaremos algoritmos de regresión de aprendizaje supervisado para predecir los índices de creencias en razonamientos lógicos y así detectar posibles sesgos.\n",
    "\n",
    "- Comenzaremos utilizando un modelo base (baseline model) como referencia para comparar con otros modelos en la resolución de nuestro problema.\n",
    "\n",
    "- Realizaremos optimización de hiperpárametros utilizando técnicas como grid search y random search.\n",
    "\n",
    "- Seleccionaremos métricas de error como MAE, MSE y RMSE, para evaluar nuestros modelos\n",
    "\n",
    "- Opcionalmente, veremos cómo transformar nuestro problema de regresión en un problema de clasificación binaria\n",
    "\n",
    "------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cll_Ia6fGmRV"
   },
   "source": [
    "## 1. Selección de características y división en conjunto de entrenamiento y conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# importación de librerías\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "jgRr-Um3GmRV"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participante</th>\n",
       "      <th>Modalidad</th>\n",
       "      <th>1_ValidezxCreencia</th>\n",
       "      <th>2_ValidezxCreencia</th>\n",
       "      <th>3_ValidezxCreencia</th>\n",
       "      <th>4_ValidezxCreencia</th>\n",
       "      <th>5_ValidezxCreencia</th>\n",
       "      <th>6_ValidezxCreencia</th>\n",
       "      <th>7_ValidezxCreencia</th>\n",
       "      <th>8_ValidezxCreencia</th>\n",
       "      <th>...</th>\n",
       "      <th>8_Aceptación</th>\n",
       "      <th>1_Correctas</th>\n",
       "      <th>2_Correctas</th>\n",
       "      <th>3_Correctas</th>\n",
       "      <th>4_Correctas</th>\n",
       "      <th>5_Correctas</th>\n",
       "      <th>6_Correctas</th>\n",
       "      <th>7_Correctas</th>\n",
       "      <th>8_Correctas</th>\n",
       "      <th>indice_creencia_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Resolución Individual</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Resolución Individual</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Resolución Individual</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Resolución Individual</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Resolución Individual</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>353</td>\n",
       "      <td>Resolución Individual Post</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>353</td>\n",
       "      <td>Resolución Individual Pre</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>354</td>\n",
       "      <td>Grupal_ws</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>354</td>\n",
       "      <td>Resolución Individual Post</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>354</td>\n",
       "      <td>Resolución Individual Pre</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>584 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Participante                   Modalidad  1_ValidezxCreencia  \\\n",
       "0               1       Resolución Individual                 0.0   \n",
       "1               2       Resolución Individual                 0.0   \n",
       "2               3       Resolución Individual                 0.0   \n",
       "3               4       Resolución Individual                 0.0   \n",
       "4               5       Resolución Individual                 0.0   \n",
       "..            ...                         ...                 ...   \n",
       "579           353  Resolución Individual Post                 0.0   \n",
       "580           353   Resolución Individual Pre                 0.0   \n",
       "581           354                   Grupal_ws                 0.0   \n",
       "582           354  Resolución Individual Post                 0.0   \n",
       "583           354   Resolución Individual Pre                 0.0   \n",
       "\n",
       "     2_ValidezxCreencia  3_ValidezxCreencia  4_ValidezxCreencia  \\\n",
       "0                   1.0                 2.0                 3.0   \n",
       "1                   1.0                 2.0                 3.0   \n",
       "2                   1.0                 2.0                 3.0   \n",
       "3                   1.0                 2.0                 3.0   \n",
       "4                   1.0                 2.0                 3.0   \n",
       "..                  ...                 ...                 ...   \n",
       "579                 1.0                 2.0                 3.0   \n",
       "580                 1.0                 2.0                 3.0   \n",
       "581                 1.0                 2.0                 3.0   \n",
       "582                 1.0                 2.0                 3.0   \n",
       "583                 1.0                 2.0                 3.0   \n",
       "\n",
       "     5_ValidezxCreencia  6_ValidezxCreencia  7_ValidezxCreencia  \\\n",
       "0                   0.0                 1.0                 2.0   \n",
       "1                   0.0                 1.0                 2.0   \n",
       "2                   0.0                 1.0                 2.0   \n",
       "3                   0.0                 1.0                 2.0   \n",
       "4                   0.0                 1.0                 2.0   \n",
       "..                  ...                 ...                 ...   \n",
       "579                 0.0                 1.0                 2.0   \n",
       "580                 0.0                 1.0                 2.0   \n",
       "581                 0.0                 1.0                 2.0   \n",
       "582                 0.0                 1.0                 2.0   \n",
       "583                 0.0                 1.0                 2.0   \n",
       "\n",
       "     8_ValidezxCreencia  ...  8_Aceptación  1_Correctas  2_Correctas  \\\n",
       "0                   3.0  ...             0            1            1   \n",
       "1                   3.0  ...             1            1            1   \n",
       "2                   3.0  ...             0            1            0   \n",
       "3                   3.0  ...             0            1            1   \n",
       "4                   3.0  ...             0            1            0   \n",
       "..                  ...  ...           ...          ...          ...   \n",
       "579                 3.0  ...             0            1            1   \n",
       "580                 3.0  ...             0            1            1   \n",
       "581                 3.0  ...             0            1            1   \n",
       "582                 3.0  ...             0            1            1   \n",
       "583                 3.0  ...             1            1            1   \n",
       "\n",
       "     3_Correctas  4_Correctas  5_Correctas  6_Correctas  7_Correctas  \\\n",
       "0              1            1            1            1            0   \n",
       "1              1            1            1            1            0   \n",
       "2              1            1            0            0            0   \n",
       "3              1            1            1            1            0   \n",
       "4              1            1            1            1            0   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "579            0            1            1            1            0   \n",
       "580            0            1            1            1            1   \n",
       "581            0            1            1            1            0   \n",
       "582            0            1            1            1            0   \n",
       "583            1            1            1            1            0   \n",
       "\n",
       "     8_Correctas  indice_creencia_norm  \n",
       "0              1                  0.25  \n",
       "1              0                  0.00  \n",
       "2              1                  0.50  \n",
       "3              1                  0.25  \n",
       "4              1                  0.50  \n",
       "..           ...                   ...  \n",
       "579            1                  0.50  \n",
       "580            1                  0.25  \n",
       "581            1                  0.50  \n",
       "582            1                  0.50  \n",
       "583            0                  0.00  \n",
       "\n",
       "[584 rows x 27 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"datos_preprocesados_grupo_1.csv\") \n",
    "df2 = pd.read_csv(\"datos_preprocesados.csv\") \n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQssXQQAGmRW"
   },
   "source": [
    "### 1.1. Indicar qué características se utilizaran durante el entrenamiento\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0it49OcGmRW"
   },
   "source": [
    "En el trabajo práctico anterior realizamos la curación de datos que creimos pertinente, obteniendo los datos arriba mostrados. A las columnas al estilo %_ValidezxCreencia se les aplicó una codificación ordinal, lo cuál puede ser que no haya sido la mejor decisión dado que no existe una relación jerárquica entre los distintos valores que tomaba esta variable. Al contar ahora con un nuevo dataframe preprocesado, se nos ocurre realizar el entrenamiento con ambos datasets, para evaluar la influencia de esta decisión en el entrenamiento de los modelos, y optar finalmente por el camino que de mejores resultados.<br>\n",
    "Para el entrenamiento descartaremos las columnas relacionadas a los sujetos, como la aceptación y la corrección de los silogismos, dado que al estar estrechamente relacionado con la variable target, estaríamos overfitteando e introduciendo sesgos en nuestro propio análisis de sesgos. \n",
    "Haremos una pequeña curación de datos al nuevo dataset obtenido y luego podremos alternar entre uno y otro. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Eliminar Aceptación y correctas \n",
    "aceptacion = ['1_Aceptación', '2_Aceptación', '3_Aceptación', '4_Aceptación',\n",
    "       '5_Aceptación', '6_Aceptación', '7_Aceptación', '8_Aceptación']\n",
    "correctas = ['1_Correctas', '2_Correctas', '3_Correctas', '4_Correctas',\n",
    "       '5_Correctas', '6_Correctas', '7_Correctas', '8_Correctas']\n",
    "\n",
    "df1.drop(aceptacion+correctas, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Participante', 'Modalidad', '1_ValidezxCreencia', '2_ValidezxCreencia',\n",
       "       '3_ValidezxCreencia', '4_ValidezxCreencia', '5_ValidezxCreencia',\n",
       "       '6_ValidezxCreencia', '7_ValidezxCreencia', '8_ValidezxCreencia',\n",
       "       'indice_creencia_norm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmGifoHwGmRX"
   },
   "source": [
    "### 1.2. Utilizar esta sección para llevar a cabo cualquier acción que consideren necesaria para pasar a la división y el posterior entrenamiento\n",
    "\n",
    "**Nota**: Recuerden insertar comentarios en el código indicando las acciones que llevan a cabo con su justificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado trabajamos sobre el nuevo datadrame adquirido, realizando una pequeña curación para el trabajo del mismo. <br>\n",
    "Primero transformamos los valores categóricos que toman las variables tipo \"Validez_sil%\" y \"Creencia_sil%\" por valores numéricos. La convención utilizada es que para un silogismo \"Válido\" o \"Creíble\", la columna toma un valor 1, en caso del silogismo ser \"Inválido\" o \"Increíble\", la columna toma valor 0. De esta forma hacemos un encoding que no jerarquiza ni prioriza un valor sobre otro, como puede llegar a entenderse en el manejo del primer data frame. <br>\n",
    "Luego de esto, eliminamos las columnas \"ValidezxCreencia_sil%\", dado que además de contener valores categóricas, dicha información ya está contenida en otras columnas que son númericas, así que no perdemos información. Por último, eliminamos las variables edad, género y grupo por los mismos motivos que fueron eliminadas en el dataframe original. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "v4lUP3M4GmRX"
   },
   "outputs": [],
   "source": [
    "# Definición de la función que transforma los valores obtenidos del df a nuestra convención\n",
    "def transform_codification(value):\n",
    "    if value == 'V' or value == 'C':\n",
    "        return 1\n",
    "    elif value == 'I':\n",
    "        return 0\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "# Aplica la transformación a las columnas de validez y creencia\n",
    "validez_columns = ['Validez_sil1', 'Validez_sil2', 'Validez_sil3', 'Validez_sil4', 'Validez_sil5', 'Validez_sil6', 'Validez_sil7', 'Validez_sil8']\n",
    "creencia_columns = ['Creencia_sil1', 'Creencia_sil2', 'Creencia_sil3', 'Creencia_sil4', 'Creencia_sil5', 'Creencia_sil6', 'Creencia_sil7', 'Creencia_sil8']\n",
    "\n",
    "for col in validez_columns + creencia_columns:\n",
    "    df2[col] = df2[col].apply(transform_codification)\n",
    "\n",
    "# Elimina las columnas de validez x creencia\n",
    "validezxcreencia_columns = ['ValidezxCreencia_sil1', 'ValidezxCreencia_sil2', 'ValidezxCreencia_sil3', 'ValidezxCreencia_sil4', 'ValidezxCreencia_sil5', 'ValidezxCreencia_sil6', 'ValidezxCreencia_sil7', 'ValidezxCreencia_sil8']\n",
    "df2.drop(validezxcreencia_columns, axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Participante', 'Modalidad', 'Edad', 'Género', 'Grupo', 'Validez_sil1',\n",
       "       'Validez_sil2', 'Validez_sil3', 'Validez_sil4', 'Validez_sil5',\n",
       "       'Validez_sil6', 'Validez_sil7', 'Validez_sil8', 'Creencia_sil1',\n",
       "       'Creencia_sil2', 'Creencia_sil3', 'Creencia_sil4', 'Creencia_sil5',\n",
       "       'Creencia_sil6', 'Creencia_sil7', 'Creencia_sil8', 'Aceptación_sil1',\n",
       "       'Aceptación_sil2', 'Aceptación_sil3', 'Aceptación_sil4',\n",
       "       'Aceptación_sil5', 'Aceptación_sil6', 'Aceptación_sil7',\n",
       "       'Aceptación_sil8', 'Correctas_sil1', 'Correctas_sil2', 'Correctas_sil3',\n",
       "       'Correctas_sil4', 'Correctas_sil5', 'Correctas_sil6', 'Correctas_sil7',\n",
       "       'Correctas_sil8', 'indice_creencia_norm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Elimina las columnas extras que eliminamos en el análisis del práctico 2\n",
    "drop_extras = [ 'Edad', 'Género', 'Grupo']\n",
    "df2.drop(drop_extras, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como dijimos en el punto 1.2, eliminamos las variables relacionadas a 'Aceptación' y 'Correctas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aceptacion2 = ['Aceptación_sil1', 'Aceptación_sil2', 'Aceptación_sil3', 'Aceptación_sil4', \n",
    "               'Aceptación_sil5', 'Aceptación_sil6', 'Aceptación_sil7', 'Aceptación_sil8'] \n",
    "correctas2 = ['Correctas_sil1', 'Correctas_sil2', 'Correctas_sil3', 'Correctas_sil4',\n",
    "              'Correctas_sil5', 'Correctas_sil6', 'Correctas_sil7', 'Correctas_sil8']\n",
    "df2.drop(aceptacion2+correctas2, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Participante', 'Modalidad', 'Validez_sil1', 'Validez_sil2',\n",
       "       'Validez_sil3', 'Validez_sil4', 'Validez_sil5', 'Validez_sil6',\n",
       "       'Validez_sil7', 'Validez_sil8', 'Creencia_sil1', 'Creencia_sil2',\n",
       "       'Creencia_sil3', 'Creencia_sil4', 'Creencia_sil5', 'Creencia_sil6',\n",
       "       'Creencia_sil7', 'Creencia_sil8', 'indice_creencia_norm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxq1jrV0GmRX"
   },
   "source": [
    "## 1.3. Dividir en conjunto de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora sí realizamos una copia de ambos dataframes en la variable df, así que para entrenar el modelo usamos la misma variable, con la diferencia que comentamos o descomentamos el df que vamos a utilizar. Luego de esto hacemos la selección de los atributos para el entrenamiento y la división del conjunto en entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hago una copia del datadrame utilizado para el entrenamiento\n",
    "#df = df1.copy()\n",
    "df = df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "6rBp_0jLGmRY"
   },
   "outputs": [],
   "source": [
    "# Indicamos las características que se utilizarán (X) y la variable objetivo (y)\n",
    "X = df.drop(['Participante', 'Modalidad', 'indice_creencia_norm'], axis=1)\n",
    "y = df['indice_creencia_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Validez_sil1', 'Validez_sil2', 'Validez_sil3', 'Validez_sil4',\n",
       "       'Validez_sil5', 'Validez_sil6', 'Validez_sil7', 'Validez_sil8',\n",
       "       'Creencia_sil1', 'Creencia_sil2', 'Creencia_sil3', 'Creencia_sil4',\n",
       "       'Creencia_sil5', 'Creencia_sil6', 'Creencia_sil7', 'Creencia_sil8'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dividir en train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GubAUeayGmRY"
   },
   "source": [
    "## 2. Modelo base\n",
    "\n",
    "En cada proyecto, es útil crear un modelo de referencia que implemente un algoritmo muy simple. Esto nos permite comparar nuestros resultados posteriores con el modelo base y ver si estamos mejorando.\n",
    "### 2.1.  Crear un modelo que siempre devuelva el índice de creencia promedio.\n",
    "\n",
    "**Ayuda:** scikit-learn cuenta con la clase [DummyRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyRegressor.html) que es muy útil para esta tarea.\n",
    "_______________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "m586r9aYGmRZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Dummy - Accuracy: -0.0022405646004968194\n",
      "Modelo Dummy - MAE: 0.2254344919786096\n",
      "Modelo Dummy - MSE: 0.0809511638880151\n",
      "Modelo Dummy - RMSE: 0.2845191801759859\n"
     ]
    }
   ],
   "source": [
    "# Crear un modelo DummyRegressor que prediga siempre el índice de creencia promedio\n",
    "dummy_model = DummyRegressor(strategy='mean')\n",
    "\n",
    "# Entrenar el modelo\n",
    "dummy_model.fit(X_train, y_train)\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "y_pred_dummy = dummy_model.predict(X_test)\n",
    "\n",
    "# Calcular métricas de error\n",
    "mae_dummy = mean_absolute_error(y_test, y_pred_dummy)\n",
    "mse_dummy = mean_squared_error(y_test, y_pred_dummy)\n",
    "rmse_dummy = np.sqrt(mse_dummy)\n",
    "score_dummy = dummy_model.score(X_test, y_test)\n",
    "\n",
    "print(\"Modelo Dummy - Accuracy:\", score_dummy)\n",
    "print(\"Modelo Dummy - MAE:\", mae_dummy)\n",
    "print(\"Modelo Dummy - MSE:\", mse_dummy)\n",
    "print(\"Modelo Dummy - RMSE:\", rmse_dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJS0-FIzGmRZ"
   },
   "source": [
    "### 2.2 Evaluación\n",
    "Una vez que hemos entrenado nuestro modelo base y obtenido predicciones para nuestro conjunto de test, es hora de que evaluamos su performance. Para la evaluación usaremos el [error absoluto medio](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html) (MAE por sus siglas en inglés).\n",
    "\n",
    "Adicionalmente, van a tener que elegir otra métrica de error y justificar su elección.\n",
    "____________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como métrica adicional utilizaremos el WMAE (error absoluto medio ponderado). El WMAE es similar al MAE (Mean Absolute Error), pero tiene en cuenta el peso de cada observación. El peso de cada observación se puede utilizar para reflejar la importancia relativa de cada observación. En este caso, estamos asignando un peso de 2 a las observaciones que son mayores que 0, y un peso de 0.5 a las observaciones que son menores que 0. Esto significa que el modelo le dará más importancia a las observaciones que son mayores que 0, dado que estas nos indican presencia de sesgos en nuestras observaciones, y menos importancia a las observaciones que son menores que 0 (que como vimos en el práctico anterior, los valores negativos de la variable target no tenía mucho interés de estudio). El resultado será un número que indica el error del modelo en la predicción de las observaciones, teniendo en cuenta los pesos de las observaciones. Un WMAE más bajo indica que el modelo es más preciso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "Z7yGdGIUGmRa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Dummy - WMAE: 0.19531840259039393\n"
     ]
    }
   ],
   "source": [
    "mae_mod_base = float(\"{:.2f}\".format(mae_dummy))\n",
    "\n",
    "# Calcular los pesos\n",
    "weights = []\n",
    "for y_i in y_test:\n",
    "    if y_i > 0:\n",
    "        weights.append(2)\n",
    "    else:\n",
    "        weights.append(0.5)\n",
    "\n",
    "# Calcular el error del modelo con MAE\n",
    "wmae = mean_absolute_error(y_test, y_pred_dummy, sample_weight=weights)\n",
    "\n",
    "print(\"Modelo Dummy - WMAE:\", wmae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNpaEgAcGmRa"
   },
   "source": [
    "Antes de pasar a la siguiente sección vamos a llevar a cabo un pequeño test para ver que nuestro modelo base no sobrepase el valor máximo para el MAE que fijamos en $0.24$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "GtVID-YYGmRa"
   },
   "outputs": [],
   "source": [
    "# no modificar esta celda\n",
    "\n",
    "def check_mae(mae):\n",
    "    if mae <= 0.24:\n",
    "        print(f\"MAE:{mae}\")\n",
    "    else:\n",
    "        raise ValueError(f'El MAE es de {mae}, necesitan un MAE menor o igual que 0.24. Revisen las características seleccionadas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "DdDoR9toGmRa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:0.23\n"
     ]
    }
   ],
   "source": [
    "check_mae(mae_mod_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMi-t3TiGmRa"
   },
   "source": [
    "## 2. Experimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBsYTyGQGmRa"
   },
   "source": [
    "### 2.1. Probando diferentes estimadores\n",
    "\n",
    "Utilice tres estimadores diferentes para la predicción del índice de creencia, obtenga las predicciones y realice la evaluación\n",
    "\n",
    "**Nota:** Pueden probar la cantidad de modelos que deseen, pero aquí en la notebook deben registrar sólo tres.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "4WXK2RN8GmRa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.2254344919786096\n",
      "WMAE: 0.19531840259039393\n"
     ]
    }
   ],
   "source": [
    "# Primer estimador\n",
    "estimador_1 = GradientBoostingRegressor(n_estimators=5, max_depth=3, random_state=42)\n",
    "\n",
    "# train\n",
    "estimador_1.fit(X_train, y_train)\n",
    "\n",
    "# predicciones\n",
    "y_pred_1 = estimador_1.predict(X_test)\n",
    "\n",
    "# evaluación\n",
    "mae_1 = mean_absolute_error(y_test, y_pred_1)\n",
    "weights_1 = []\n",
    "for y_i in y_test:\n",
    "    if y_i > 0:\n",
    "        weights_1.append(2)\n",
    "    else:\n",
    "        weights_1.append(0.5)\n",
    "wmae_1 = mean_absolute_error(y_test, y_pred_1, sample_weight=weights_1)\n",
    "print(\"MAE:\", mae_1)\n",
    "print(\"WMAE:\", wmae_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.22490808823529412\n",
      "WMAE: 0.19528197517539125\n"
     ]
    }
   ],
   "source": [
    "# Segundo estimador\n",
    "estimator_2 = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# train\n",
    "estimator_2.fit(X_train, y_train)\n",
    "\n",
    "# predicciones\n",
    "y_pred_2 = estimator_2.predict(X_test)\n",
    "\n",
    "# evaluación\n",
    "mae_2 = mean_absolute_error(y_test, y_pred_2)\n",
    "weights_2 = []\n",
    "for y_i in y_test:\n",
    "    if y_i > 0:\n",
    "        weights_2.append(2)\n",
    "    else:\n",
    "        weights_2.append(0.5)\n",
    "wmae_2 = mean_absolute_error(y_test, y_pred_2, sample_weight=weights_2)\n",
    "print(\"MAE:\", mae_2)\n",
    "print(\"WMAE:\", wmae_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "sFfLl4RuGmRb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 3: 0.22017045454545456\n",
      "WMAE 3: 0.19495412844036697\n"
     ]
    }
   ],
   "source": [
    "# Tercer estimador: KNeighborsRegressor\n",
    "estimador_3 = KNeighborsRegressor(n_neighbors=3)  \n",
    "\n",
    "# train\n",
    "estimador_3.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_3 = estimador_3.predict(X_test)\n",
    "\n",
    "# evaluación\n",
    "mae_3 = mean_absolute_error(y_test, y_pred_3)\n",
    "weights_3 = []\n",
    "for y_i in y_test:\n",
    "    if y_i > 0:\n",
    "        weights_3.append(2)\n",
    "    else:\n",
    "        weights_3.append(0.5)\n",
    "wmae_3 = mean_absolute_error(y_test, y_pred_3, sample_weight=weights_3)\n",
    "print(\"MAE 3:\", mae_3)\n",
    "print(\"WMAE 3:\", wmae_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jjZxWewEGmRb"
   },
   "source": [
    "### 2.2. Optimización de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMGQvTd6GmRb"
   },
   "source": [
    "Seleccione un estimador de los utilizados en el punto anterior y lleve a cabo una optimización de hiperparámetros utilizando  [Grid Search](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) o [Random Search](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html).\n",
    "\n",
    "Registre las mejores métricas alcanzadas y los valores de los hiperparámetros utilizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "4EJd0GlcGmRb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Mejor MAE: 0.23547458842214422\n",
      "MAE del modelo optimizado: 0.2244986631016043\n",
      "WMAE del modelo optimizado: 0.19525364274150028\n"
     ]
    }
   ],
   "source": [
    "estimator_2 = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Hiperparámetros a ajustar\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  \n",
    "    'max_depth': [None, 5, 10, 15, 20, 25, 30],  \n",
    "    'min_samples_split': [2, 5, 10],  \n",
    "    'min_samples_leaf': [1, 2, 4]  \n",
    "}\n",
    "\n",
    "# Crear un objeto GridSearchCV\n",
    "grid_search = GridSearchCV(estimator_2, param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener los mejores hiperparámetros y la mejor puntuación\n",
    "best_params = grid_search.best_params_\n",
    "best_mae = -grid_search.best_score_ \n",
    "\n",
    "# Modelo con los mejores hiperparámetros\n",
    "estimator_opt = RandomForestRegressor(**best_params, random_state=42)\n",
    "estimator_opt.fit(X_train, y_train)\n",
    "\n",
    "# predicciones\n",
    "y_pred = estimator_opt.predict(X_test)\n",
    "\n",
    "# evaluacion\n",
    "mae_est_opt = mean_absolute_error(y_test, y_pred)\n",
    "wmae_est_opt = mean_absolute_error(y_test, y_pred, sample_weight=weights)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Mejores hiperparámetros:\", best_params)\n",
    "print(\"Mejor MAE:\", best_mae)\n",
    "print(\"MAE del modelo optimizado:\", mae_est_opt)\n",
    "print(\"WMAE del modelo optimizado:\", wmae_est_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'weights': 'uniform', 'p': 1, 'n_neighbors': 3}\n",
      "Mejor MAE: 0.23311483739837396\n",
      "MAE del modelo optimizado: 0.22017045454545456\n",
      "WMAE del modelo optimizado: 0.19495412844036697\n"
     ]
    }
   ],
   "source": [
    "estimador = KNeighborsRegressor()  \n",
    "param_dist = {\n",
    "    'n_neighbors': np.arange(1, 30),  \n",
    "    'weights': ['uniform', 'distance'],  \n",
    "    'p': [1, 2]  \n",
    "}\n",
    "\n",
    "# Crear un objeto RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimador, param_distributions=param_dist, n_iter=30, cv=10, scoring='neg_mean_absolute_error')\n",
    "\n",
    "# Realizar la búsqueda de hiperparámetros en los datos de entrenamiento\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener los mejores hiperparámetros y la mejor puntuación\n",
    "best_params = random_search.best_params_\n",
    "best_mae = -random_search.best_score_  \n",
    "\n",
    "# Crear un modelo con los mejores hiperparámetros encontrados\n",
    "estimador_3_opt = KNeighborsRegressor(**best_params)\n",
    "\n",
    "# Entrenamiento con los mejores hiperparámetros\n",
    "estimador_3_opt.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones con el modelo optimizado\n",
    "y_pred_3_opt = estimador_3_opt.predict(X_test)\n",
    "\n",
    "# Evaluación con MAE\n",
    "mae_3_opt = mean_absolute_error(y_test, y_pred_3_opt)\n",
    "weights_3_opt = []\n",
    "for y_i in y_test:\n",
    "    if y_i > 0:\n",
    "        weights_3_opt.append(2)\n",
    "    else:\n",
    "        weights_3_opt.append(0.5)\n",
    "wmae_3_opt = mean_absolute_error(y_test, y_pred_3_opt, sample_weight=weights_3_opt)\n",
    "\n",
    "#Imprimo resultados\n",
    "print(\"Mejores hiperparámetros:\", best_params)\n",
    "print(\"Mejor MAE:\", best_mae)\n",
    "print(\"MAE del modelo optimizado:\", mae_3_opt)\n",
    "print(\"WMAE del modelo optimizado:\", wmae_3_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado a la naturaleza \"random\" de esta celda, imprimimos los resultados obtenidos por nosotros acá, en caso de correr todas las celdas de vuelta y no replicar nuestros resultados: \n",
    "<br></br>\n",
    "Mejores hiperparámetros: {'weights': 'uniform', 'p': 1, 'n_neighbors': 3}<br>\n",
    "Mejor MAE: 0.23311483739837396<br>\n",
    "MAE del modelo optimizado: 0.22017045454545456<br>\n",
    "WMAE del modelo optimizado: 0.19495412844036697<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "ItnHP2oKGmRc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:0.22017045454545456\n"
     ]
    }
   ],
   "source": [
    "check_mae(mae_3_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusiones\n",
    "El mejor modelo que pudimos entrenar es el KNeighborsRegressor, obteniendo un MAE de 0.22017 y un WMAE de 0.19495, frente a los scores obtenidos con el modelo dummy (MAE: 0.22543 y WMAE: 0.19532)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dj62R8BOGmRc"
   },
   "source": [
    "## 3. Ingeniería de características y re-entrenamiento del modelo\n",
    "\n",
    "Como ya habrán podido observar a lo largo de la diplomatura, mucho de los procesos en ciencia de datos son iterativos. Cuando entrenamos modelos, esto implica agregar y eliminar características, modificar el escalado y la codificación, y otros tipos de acciones que nos permitan mejorar la performance de nuestro modelo.\n",
    "\n",
    "Aquí están algunas acciones que pueden llevar a cabo para mejorar el rendimiento del modelo:\n",
    "<br></br>\n",
    "- Agregar nuevas características a los datos. Esto puede ayudar al modelo a aprender más sobre los datos y a hacer mejores predicciones.\n",
    "\n",
    "- Eliminar características irrelevantes de los datos. Esto puede ayudar al modelo a evitar el sobreajuste y a mejorar su generalización.\n",
    "\n",
    "- Modificar el escalado de los datos. Esto puede ayudar al modelo a aprender más rápido y a hacer mejores predicciones.\n",
    "\n",
    "- Modificar la codificación de los datos. Esto puede ayudar al modelo a entender mejor los datos y a hacer mejores predicciones.\n",
    "\n",
    "\n",
    "<br></br>\n",
    "Una vez que hayan realizado alguna/s de estas acciones, deben reentrenar el modelo utilizado en el punto anterior.\n",
    "\n",
    "Finalmente, recuerden registrar las métricas de error, esto les ayudará a determinar si con estas acciones han mejorado el rendimiento del modelo.\n",
    "__________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos nuevamente el dataset n°2, que fue el que nos dio mejores resultados. En esta instancia, nos quedaremos con las mismas features elegidas pero agregaremos también la columna de 'Modalidad'. El problema es que esta columna contiene datos categóricos sobre la modalidad de resolución de la actividad, por lo que debemos hacer una codificación para que el modelo pueda entrenar con esta columna extra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Modalidad', 'Validez_sil1', 'Validez_sil2', 'Validez_sil3',\n",
       "       'Validez_sil4', 'Validez_sil5', 'Validez_sil6', 'Validez_sil7',\n",
       "       'Validez_sil8', 'Creencia_sil1', 'Creencia_sil2', 'Creencia_sil3',\n",
       "       'Creencia_sil4', 'Creencia_sil5', 'Creencia_sil6', 'Creencia_sil7',\n",
       "       'Creencia_sil8', 'indice_creencia_norm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cargamos los datos y eliminamos atributos previamente descartados, a excepción de modalidad\n",
    "df = pd.read_csv(\"datos_preprocesados.csv\") \n",
    "\n",
    "df.drop(validezxcreencia_columns, axis=1, inplace=True)\n",
    "df.drop(drop_extras, axis=1, inplace=True)\n",
    "df.drop(aceptacion2+correctas2, axis=1, inplace=True)\n",
    "df.drop('Participante', axis=1, inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Hacemos la división en train y test, para luego hacer el OHE\n",
    "X = df.drop(['indice_creencia_norm'], axis=1)\n",
    "y = df['indice_creencia_norm']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de train: 408 filas y 17 columnas.\n",
      "Conjunto de test: 176 filas y 17 columnas. \n"
     ]
    }
   ],
   "source": [
    "#Verificamos la cantidad de filas y columnas\n",
    "print(f\"\"\"Conjunto de train: {X_train.shape[0]} filas y {X_train.shape[1]} columnas.\n",
    "Conjunto de test: {X_test.shape[0]} filas y {X_test.shape[1]} columnas. \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolución Individual\n",
      "Resolución Grupal\n",
      "Grupal entre sujetos\n",
      "Resolución Individual Post\n",
      "Resolución Individual Pre\n"
     ]
    }
   ],
   "source": [
    "print(*X['Modalidad'].unique(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Realizamos el encoder para cada set\n",
    "ohe_enc = OneHotEncoder(sparse_output=False)\n",
    "mod_enc_train = ohe_enc.fit_transform(X_train[['Modalidad']])\n",
    "mod_enc_test = ohe_enc.transform(X_test[['Modalidad']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(408, 5)\n",
      "(176, 5)\n"
     ]
    }
   ],
   "source": [
    "print(mod_enc_train.shape)\n",
    "print(mod_enc_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Reseteamos el índice y concatenamos con el df anterior, sin la columna de modalidad ya que dicha columna se encuentra codeada ya\n",
    "X_train_encoded = pd.concat([X_train.drop('Modalidad', axis=1).reset_index(drop=True), \n",
    "                            pd.DataFrame(mod_enc_train)], axis=1)\n",
    "\n",
    "X_test_encoded = pd.concat([X_test.drop('Modalidad', axis=1).reset_index(drop=True), \n",
    "                           pd.DataFrame(mod_enc_test)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de train con columna categórica codificada: 408 filas y 21 columnas.\n",
      "Conjunto de test con columna categórica codificada: 176 filas y 21 columnas. \n"
     ]
    }
   ],
   "source": [
    "#Verificamos que tengamos la cantidad de filas y columnas correctas \n",
    "print(f\"\"\"Conjunto de train con columna categórica codificada: {X_train_encoded.shape[0]} filas y {X_train_encoded.shape[1]} columnas.\n",
    "Conjunto de test con columna categórica codificada: {X_test_encoded.shape[0]} filas y {X_test_encoded.shape[1]} columnas. \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eran 5 categorías y eliminamos la variable original ('Modalidad') por lo cual deberían haberse agregado 4 columnas (5-1). Como vemos efectivamente es así, además el número de filas se mantuvo intacto, como debe ser. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Le ponemos las etiquetas correctas a las variables codeadas\n",
    "X_train_enc_2 = pd.concat([X_train.reset_index(drop=True),\n",
    "                              pd.DataFrame(mod_enc_train, columns = ohe_enc.categories_[0])],  axis = 1)\n",
    "X_test_enc_2 = pd.concat([X_test.reset_index(drop=True),\n",
    "                              pd.DataFrame(mod_enc_test, columns = ohe_enc.categories_[0])],  axis = 1)\n",
    "\n",
    "X_train_enc_2.drop('Modalidad', axis=1, inplace=True)\n",
    "X_test_enc_2.drop('Modalidad', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Realizamos la codificación de las columnas validez y creencia\n",
    "for col in validez_columns + creencia_columns:\n",
    "    X_train_enc_2[col] = X_train_enc_2[col].apply(transform_codification)\n",
    "    \n",
    "for col in validez_columns + creencia_columns:\n",
    "    X_test_enc_2[col] = X_test_enc_2[col].apply(transform_codification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Validez_sil1</th>\n",
       "      <th>Validez_sil2</th>\n",
       "      <th>Validez_sil3</th>\n",
       "      <th>Validez_sil4</th>\n",
       "      <th>Validez_sil5</th>\n",
       "      <th>Validez_sil6</th>\n",
       "      <th>Validez_sil7</th>\n",
       "      <th>Validez_sil8</th>\n",
       "      <th>Creencia_sil1</th>\n",
       "      <th>Creencia_sil2</th>\n",
       "      <th>...</th>\n",
       "      <th>Creencia_sil4</th>\n",
       "      <th>Creencia_sil5</th>\n",
       "      <th>Creencia_sil6</th>\n",
       "      <th>Creencia_sil7</th>\n",
       "      <th>Creencia_sil8</th>\n",
       "      <th>Grupal entre sujetos</th>\n",
       "      <th>Resolución Grupal</th>\n",
       "      <th>Resolución Individual</th>\n",
       "      <th>Resolución Individual Post</th>\n",
       "      <th>Resolución Individual Pre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>408 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Validez_sil1  Validez_sil2  Validez_sil3  Validez_sil4  Validez_sil5  \\\n",
       "0               1             1             0             0             1   \n",
       "1               1             1             0             0             1   \n",
       "2               1             1             0             0             1   \n",
       "3               1             1             0             0             1   \n",
       "4               1             1             0             0             1   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "403             1             1             0             0             1   \n",
       "404             1             1             0             0             1   \n",
       "405             1             1             0             0             1   \n",
       "406             1             1             0             0             1   \n",
       "407             1             1             0             0             1   \n",
       "\n",
       "     Validez_sil6  Validez_sil7  Validez_sil8  Creencia_sil1  Creencia_sil2  \\\n",
       "0               1             0             0              1              0   \n",
       "1               1             0             0              1              0   \n",
       "2               1             0             0              1              0   \n",
       "3               1             0             0              1              0   \n",
       "4               1             0             0              1              0   \n",
       "..            ...           ...           ...            ...            ...   \n",
       "403             1             0             0              1              0   \n",
       "404             1             0             0              1              0   \n",
       "405             1             0             0              1              0   \n",
       "406             1             0             0              1              0   \n",
       "407             1             0             0              1              0   \n",
       "\n",
       "     ...  Creencia_sil4  Creencia_sil5  Creencia_sil6  Creencia_sil7  \\\n",
       "0    ...              0              1              0              1   \n",
       "1    ...              0              1              0              1   \n",
       "2    ...              0              1              0              1   \n",
       "3    ...              0              1              0              1   \n",
       "4    ...              0              1              0              1   \n",
       "..   ...            ...            ...            ...            ...   \n",
       "403  ...              0              1              0              1   \n",
       "404  ...              0              1              0              1   \n",
       "405  ...              0              1              0              1   \n",
       "406  ...              0              1              0              1   \n",
       "407  ...              0              1              0              1   \n",
       "\n",
       "     Creencia_sil8  Grupal entre sujetos  Resolución Grupal  \\\n",
       "0                0                   0.0                0.0   \n",
       "1                0                   0.0                1.0   \n",
       "2                0                   0.0                1.0   \n",
       "3                0                   0.0                1.0   \n",
       "4                0                   0.0                1.0   \n",
       "..             ...                   ...                ...   \n",
       "403              0                   0.0                0.0   \n",
       "404              0                   0.0                1.0   \n",
       "405              0                   0.0                0.0   \n",
       "406              0                   0.0                0.0   \n",
       "407              0                   0.0                0.0   \n",
       "\n",
       "     Resolución Individual  Resolución Individual Post  \\\n",
       "0                      0.0                         1.0   \n",
       "1                      0.0                         0.0   \n",
       "2                      0.0                         0.0   \n",
       "3                      0.0                         0.0   \n",
       "4                      0.0                         0.0   \n",
       "..                     ...                         ...   \n",
       "403                    1.0                         0.0   \n",
       "404                    0.0                         0.0   \n",
       "405                    0.0                         0.0   \n",
       "406                    1.0                         0.0   \n",
       "407                    0.0                         1.0   \n",
       "\n",
       "     Resolución Individual Pre  \n",
       "0                          0.0  \n",
       "1                          0.0  \n",
       "2                          0.0  \n",
       "3                          0.0  \n",
       "4                          0.0  \n",
       "..                         ...  \n",
       "403                        0.0  \n",
       "404                        0.0  \n",
       "405                        1.0  \n",
       "406                        0.0  \n",
       "407                        0.0  \n",
       "\n",
       "[408 rows x 21 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_enc_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora sí, probamos el mejor modelo obtenido (KNeighborsRegressor) con una optimización de hiperparámetros, para ver si el rendimiento mejora con las nuevas columnas incorporadas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 3: 0.28740530303030304\n",
      "WMAE 3: 0.26620795107033635\n"
     ]
    }
   ],
   "source": [
    "estimador_3 = KNeighborsRegressor(n_neighbors=3)  \n",
    "\n",
    "# train\n",
    "estimador_3.fit(X_train_enc_2, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_3 = estimador_3.predict(X_test_enc_2)\n",
    "\n",
    "# evaluación\n",
    "mae_3 = mean_absolute_error(y_test, y_pred_3)\n",
    "weights_3 = []\n",
    "for y_i in y_test:\n",
    "    if y_i > 0:\n",
    "        weights_3.append(2)\n",
    "    else:\n",
    "        weights_3.append(0.5)\n",
    "wmae_3 = mean_absolute_error(y_test, y_pred_3, sample_weight=weights_3)\n",
    "print(\"MAE 3:\", mae_3)\n",
    "print(\"WMAE 3:\", wmae_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'weights': 'uniform', 'p': 2, 'n_neighbors': 18}\n",
      "Mejor MAE: 0.23727981029810294\n",
      "MAE del modelo optimizado: 0.2267992424242424\n",
      "WMAE del modelo optimizado: 0.19877675840978593\n"
     ]
    }
   ],
   "source": [
    "estimador = KNeighborsRegressor()  \n",
    "param_dist = {\n",
    "    'n_neighbors': np.arange(1, 30),  \n",
    "    'weights': ['uniform', 'distance'],  \n",
    "    'p': [1, 2]  \n",
    "}\n",
    "\n",
    "# Crear un objeto RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimador, param_distributions=param_dist, n_iter=30, cv=10, scoring='neg_mean_absolute_error', random_state=42)\n",
    "\n",
    "# Realizar la búsqueda de hiperparámetros en los datos de entrenamiento\n",
    "random_search.fit(X_train_enc_2, y_train)\n",
    "\n",
    "# Obtener los mejores hiperparámetros y la mejor puntuación\n",
    "best_params = random_search.best_params_\n",
    "best_mae = -random_search.best_score_  \n",
    "\n",
    "# Crear un modelo con los mejores hiperparámetros encontrados\n",
    "estimador_3_opt = KNeighborsRegressor(**best_params)\n",
    "\n",
    "# Entrenamiento con los mejores hiperparámetros\n",
    "estimador_3_opt.fit(X_train_enc_2, y_train)\n",
    "\n",
    "# Predicciones con el modelo optimizado\n",
    "y_pred_3_opt = estimador_3_opt.predict(X_test_enc_2)\n",
    "\n",
    "# Evaluación\n",
    "mae_3_opt = mean_absolute_error(y_test, y_pred_3_opt)\n",
    "weights_3_opt = []\n",
    "for y_i in y_test:\n",
    "    if y_i > 0:\n",
    "        weights_3_opt.append(2)\n",
    "    else:\n",
    "        weights_3_opt.append(0.5)\n",
    "wmae_3_opt = mean_absolute_error(y_test, y_pred_3_opt, sample_weight=weights_3_opt)\n",
    "\n",
    "#Imprimimos resultados\n",
    "print(\"Mejores hiperparámetros:\", best_params)\n",
    "print(\"Mejor MAE:\", best_mae)\n",
    "print(\"MAE del modelo optimizado:\", mae_3_opt)\n",
    "print(\"WMAE del modelo optimizado:\", wmae_3_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4l-1MKKGmRc"
   },
   "source": [
    "### 3.1. Evaluación\n",
    "\n",
    "Atendiendo a lo realizado hasta ahora, responda las siguientes preguntas:\n",
    "- ¿Observan diferencias en el rendimiento del modelo base con el que empezaron y el de los diferentes modelos entrenados posteriormente?\n",
    "\n",
    "- ¿Hubo diferencias en el rendimiento del modelo con parámetros optimizados antes y después de trabajar con las características?¿Por qué considera que sucede esto?\n",
    "_____________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el mejor modelo logramos alcanzar un MAE de 0.2202, en contraste con el MAE de 0.2254 obtenido utilizando el modelo dummy. Aunque esta mejora puede parecer modesta a primera vista, consideremos que nuestra variable objetivo se encuentra en el rango de -1 a 1, y en su mayoría toma valores en el intervalo de 0 a 1 (valores pequeños), por lo que esta diferencia es apreciable. <br>\n",
    "\n",
    "Destacamos que el rendimiento de los modelos mejoró significativamente con el conjunto de datos preprocesado adquirido en comparación al dataset preprocesado de trabajos anteriores. Por este motivo, observamos que la decisión de utilizar una codificación ordinal para la variable 'ValidezxCreencia' no fue la más acertada.<br>\n",
    "\n",
    "En cuanto a la inclusión de la variable 'Modalidad', no obtuvimos mejoras significativas. Es posible que esto se deba a la codificación utilizada previamente para las columnas 'Validez' y 'Creencia'. Consideramos que una opción más efectiva podría ser aplicar la codificación 'One-Hot Encoding' (OHE) para cada una de estas columnas. Por ejemplo, en lugar de tener 'Validez_sil1' y 'Creencia_sil1' como columnas individuales, podríamos crear columnas binarias separadas, como 'Validez_sil1_V', 'Validez_sil1_I', 'Creencia_sil1_C', 'Creencia_sil1_I', y así sucesivamente para cada silogismo. <br>\n",
    "\n",
    "Como posible mejora al modelo, se recomienda hacer la codificación OHE para cada una de estas columnas y revisar si así mejora el modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eq2Y-UmqGmRd"
   },
   "source": [
    "## 4. (Opcional) Replanteando nuestro problema\n",
    "\n",
    "A lo largo de esta actividad hemos abordado el problema de predecir el índice de creencia. Este índice es muy útil para observar la polarización en las respuestas y analizar aspectos más sútiles de la problemática.\n",
    "\n",
    "Sin embargo, podríamos simplemente querer predecir si tienen lugar o no dichos sesgos, sin importar su grado, con lo cual podríamos replantear nuestro problema como un problema de clasificación binaria. En este tipo de problemas, el objetivo es predecir si una instancia pertenece a una clase o a otra. En nuestro caso, las dos clases son \"presencia de sesgos\" y \"ausencia de sesgos\".\n",
    "\n",
    "\n",
    "Para hacer esto, podemos modificar nuestra columna con la variable objetivo. Los valores positivos se reemplazarán con la etiqueta $1$, que indicarán la presencia de sesgos. Mientras que, los valores iguales o menores que $0$ se reemplazarán con la etiqueta $0$, que indicarán la ausencia de sesgos.\n",
    "\n",
    "Como ejercicio opcional, los invitamos a que entrenen un modelo que emplee algoritmos de clasificación para predecir la ausencia o presencia de sesgos de creencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participante</th>\n",
       "      <th>Modalidad</th>\n",
       "      <th>Edad</th>\n",
       "      <th>Género</th>\n",
       "      <th>Grupo</th>\n",
       "      <th>Validez_sil1</th>\n",
       "      <th>Validez_sil2</th>\n",
       "      <th>Validez_sil3</th>\n",
       "      <th>Validez_sil4</th>\n",
       "      <th>Validez_sil5</th>\n",
       "      <th>...</th>\n",
       "      <th>Correctas_sil1</th>\n",
       "      <th>Correctas_sil2</th>\n",
       "      <th>Correctas_sil3</th>\n",
       "      <th>Correctas_sil4</th>\n",
       "      <th>Correctas_sil5</th>\n",
       "      <th>Correctas_sil6</th>\n",
       "      <th>Correctas_sil7</th>\n",
       "      <th>Correctas_sil8</th>\n",
       "      <th>indice_creencia_norm</th>\n",
       "      <th>sesgos_presentes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Resolución Individual</td>\n",
       "      <td>18</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>V</td>\n",
       "      <td>V</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>V</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Resolución Individual</td>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>V</td>\n",
       "      <td>V</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>V</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Resolución Individual</td>\n",
       "      <td>20</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>V</td>\n",
       "      <td>V</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>V</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Participante              Modalidad  Edad Género  Grupo Validez_sil1  \\\n",
       "0             1  Resolución Individual    18      M      0            V   \n",
       "1             2  Resolución Individual    23      F      0            V   \n",
       "2             3  Resolución Individual    20      F      0            V   \n",
       "\n",
       "  Validez_sil2 Validez_sil3 Validez_sil4 Validez_sil5  ... Correctas_sil1  \\\n",
       "0            V            I            I            V  ...              1   \n",
       "1            V            I            I            V  ...              1   \n",
       "2            V            I            I            V  ...              1   \n",
       "\n",
       "  Correctas_sil2 Correctas_sil3 Correctas_sil4 Correctas_sil5 Correctas_sil6  \\\n",
       "0              1              1              1              1              1   \n",
       "1              1              1              1              1              1   \n",
       "2              0              1              1              0              0   \n",
       "\n",
       "  Correctas_sil7 Correctas_sil8 indice_creencia_norm sesgos_presentes  \n",
       "0              0              1                 0.25                1  \n",
       "1              0              0                 0.00                0  \n",
       "2              0              1                 0.50                1  \n",
       "\n",
       "[3 rows x 47 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"datos_preprocesados.csv\")\n",
    "df['sesgos_presentes'] = df['indice_creencia_norm'].apply(lambda x: 1 if x > 0 else 0)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Participante', 'Modalidad', 'Edad', 'Género', 'Grupo', 'Validez_sil1',\n",
       "       'Validez_sil2', 'Validez_sil3', 'Validez_sil4', 'Validez_sil5',\n",
       "       'Validez_sil6', 'Validez_sil7', 'Validez_sil8', 'Creencia_sil1',\n",
       "       'Creencia_sil2', 'Creencia_sil3', 'Creencia_sil4', 'Creencia_sil5',\n",
       "       'Creencia_sil6', 'Creencia_sil7', 'Creencia_sil8',\n",
       "       'ValidezxCreencia_sil1', 'ValidezxCreencia_sil2',\n",
       "       'ValidezxCreencia_sil3', 'ValidezxCreencia_sil4',\n",
       "       'ValidezxCreencia_sil5', 'ValidezxCreencia_sil6',\n",
       "       'ValidezxCreencia_sil7', 'ValidezxCreencia_sil8', 'Aceptación_sil1',\n",
       "       'Aceptación_sil2', 'Aceptación_sil3', 'Aceptación_sil4',\n",
       "       'Aceptación_sil5', 'Aceptación_sil6', 'Aceptación_sil7',\n",
       "       'Aceptación_sil8', 'Correctas_sil1', 'Correctas_sil2', 'Correctas_sil3',\n",
       "       'Correctas_sil4', 'Correctas_sil5', 'Correctas_sil6', 'Correctas_sil7',\n",
       "       'Correctas_sil8', 'indice_creencia_norm', 'sesgos_presentes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Validez_sil1', 'Validez_sil2', 'Validez_sil3', 'Validez_sil4',\n",
       "       'Validez_sil5', 'Validez_sil6', 'Validez_sil7', 'Validez_sil8',\n",
       "       'Creencia_sil1', 'Creencia_sil2', 'Creencia_sil3', 'Creencia_sil4',\n",
       "       'Creencia_sil5', 'Creencia_sil6', 'Creencia_sil7', 'Creencia_sil8',\n",
       "       'sesgos_presentes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Eliminamos la vieja columna target y el resto de las columnas innecesarias\n",
    "columnas_drop = ['Modalidad', 'Participante', 'Edad', 'Género', 'Grupo', 'ValidezxCreencia_sil1', 'ValidezxCreencia_sil2',\n",
    "       'ValidezxCreencia_sil3', 'ValidezxCreencia_sil4',\n",
    "       'ValidezxCreencia_sil5', 'ValidezxCreencia_sil6',\n",
    "       'ValidezxCreencia_sil7', 'ValidezxCreencia_sil8', 'Aceptación_sil1',\n",
    "       'Aceptación_sil2', 'Aceptación_sil3', 'Aceptación_sil4',\n",
    "       'Aceptación_sil5', 'Aceptación_sil6', 'Aceptación_sil7',\n",
    "       'Aceptación_sil8', 'Correctas_sil1', 'Correctas_sil2', 'Correctas_sil3',\n",
    "       'Correctas_sil4', 'Correctas_sil5', 'Correctas_sil6', 'Correctas_sil7',\n",
    "       'Correctas_sil8', 'indice_creencia_norm']\n",
    "\n",
    "df.drop(columnas_drop, axis=1, inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in validez_columns + creencia_columns:\n",
    "    df[col] = df[col].apply(transform_codification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Validez_sil1</th>\n",
       "      <th>Validez_sil2</th>\n",
       "      <th>Validez_sil3</th>\n",
       "      <th>Validez_sil4</th>\n",
       "      <th>Validez_sil5</th>\n",
       "      <th>Validez_sil6</th>\n",
       "      <th>Validez_sil7</th>\n",
       "      <th>Validez_sil8</th>\n",
       "      <th>Creencia_sil1</th>\n",
       "      <th>Creencia_sil2</th>\n",
       "      <th>Creencia_sil3</th>\n",
       "      <th>Creencia_sil4</th>\n",
       "      <th>Creencia_sil5</th>\n",
       "      <th>Creencia_sil6</th>\n",
       "      <th>Creencia_sil7</th>\n",
       "      <th>Creencia_sil8</th>\n",
       "      <th>sesgos_presentes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Validez_sil1  Validez_sil2  Validez_sil3  Validez_sil4  Validez_sil5  \\\n",
       "0             1             1             0             0             1   \n",
       "1             1             1             0             0             1   \n",
       "2             1             1             0             0             1   \n",
       "\n",
       "   Validez_sil6  Validez_sil7  Validez_sil8  Creencia_sil1  Creencia_sil2  \\\n",
       "0             1             0             0              1              0   \n",
       "1             1             0             0              1              0   \n",
       "2             1             0             0              1              0   \n",
       "\n",
       "   Creencia_sil3  Creencia_sil4  Creencia_sil5  Creencia_sil6  Creencia_sil7  \\\n",
       "0              1              0              1              0              1   \n",
       "1              1              0              1              0              1   \n",
       "2              1              0              1              0              1   \n",
       "\n",
       "   Creencia_sil8  sesgos_presentes  \n",
       "0              0                 1  \n",
       "1              0                 0  \n",
       "2              0                 1  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df.drop(['sesgos_presentes'], axis=1)\n",
    "y = df['sesgos_presentes']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=50,  stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Dummy Classifier - Accuracy: 0.6761363636363636\n",
      "Modelo Dummy Classifier - Precision: 0.6761363636363636\n",
      "Modelo Dummy Classifier - Recall: 1.0\n",
      "Modelo Dummy Classifier - F1 Score: 0.8067796610169491\n",
      "Modelo Dummy Classifier - Confusion Matrix:\n",
      " [[  0  57]\n",
      " [  0 119]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Crear un modelo DummyClassifier que prediga la clase mayoritaria (0 o 1)\n",
    "dummy_classifier = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "# Entrenar el modelo\n",
    "dummy_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "y_pred_dummy = dummy_classifier.predict(X_test)\n",
    "\n",
    "# Calcular métricas de clasificación\n",
    "accuracy_dummy = accuracy_score(y_test, y_pred_dummy)\n",
    "precision_dummy = precision_score(y_test, y_pred_dummy)\n",
    "recall_dummy = recall_score(y_test, y_pred_dummy)\n",
    "f1_score_dummy = f1_score(y_test, y_pred_dummy)\n",
    "confusion_matrix_dummy = confusion_matrix(y_test, y_pred_dummy)\n",
    "\n",
    "print(\"Modelo Dummy Classifier - Accuracy:\", accuracy_dummy)\n",
    "print(\"Modelo Dummy Classifier - Precision:\", precision_dummy)\n",
    "print(\"Modelo Dummy Classifier - Recall:\", recall_dummy)\n",
    "print(\"Modelo Dummy Classifier - F1 Score:\", f1_score_dummy)\n",
    "print(\"Modelo Dummy Classifier - Confusion Matrix:\\n\", confusion_matrix_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6761363636363636\n",
      "Precision: 0.6761363636363636\n",
      "Recall: 1.0\n",
      "F1-score: 0.8067796610169491\n",
      "Confusion Matrix:\n",
      "[[  0  57]\n",
      " [  0 119]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(criterion='entropy', max_depth= 15, min_samples_leaf= 8, min_samples_split= 5, n_estimators= 152, class_weight='balanced', random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de clases en el conjunto de prueba:\n",
      "{0: 57, 1: 119}\n"
     ]
    }
   ],
   "source": [
    "# Verificar la distribución de clases en el conjunto de prueba\n",
    "unique_classes, class_counts = np.unique(y_test, return_counts=True)\n",
    "class_distribution = dict(zip(unique_classes, class_counts))\n",
    "\n",
    "print(\"Distribución de clases en el conjunto de prueba:\")\n",
    "print(class_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección, observamos que el rendimiento de un modelo dummy que predice siempre el valor más frecuente y un modelo Random Forest de clasificación es exactamente igual. Sin embargo, al profundizar en la evaluación, notamos un desequilibrio significativo en la distribución de clases en el conjunto de prueba. Contamos con 53 muestras de la clase 0 y 123 muestras de la clase 1. Este desequilibrio puede explicar por qué ambos modelos obtienen resultados similares, ya que el modelo tiende a clasificar predominantemente la clase mayoritaria (clase 1) debido a su mayor presencia. Efectivamente podemos observar en la matriz de confusión que el modelo aprendió a clasificar siempre el valor 1. <br>\n",
    "\n",
    "Este hallazgo nos lleva a cuestionar la utilización un modelo de clasificación binaria en este contexto. En primer lugar, las respuestas no sesgadas deberían reflejar una cierta distribución alrededor del valor 0, por lo que un corte 0 para las respuestas no sesgadas puede ser una opción muy agresiva y que no tiene en cuenta factores donde los sujetos pueden equivocarse no necesariamente por sesgos, sino por la complejidad propia del silogismo. Por otro lado, la presencia de respuestas sesgadas contribuye al desequilibrio del conjunto de datos, lo que afecta negativamente el rendimiento del modelo. <br>\n",
    "\n",
    "Para abordar este problema, proponemos algunas soluciones potenciales:\n",
    " \n",
    "- Ajustar el umbral de clasificación: En lugar de utilizar un umbral estricto en 0, podríamos considerar un rango de valores alrededor de cero como indicativo de respuestas no sesgadas.\n",
    "\n",
    "- Técnicas de remuestreo: Podríamos aplicar técnicas como oversampling o undersampling para equilibrar las clases en el conjunto de datos. Sin embargo, estas técnicas conllevan ciertas limitaciones, como la pérdida de datos en el caso del undersampling o el riesgo de overfitting en el oversampling.\n",
    "\n",
    "- Exploración de modelos diferentes: También podríamos considerar la exploración de otros modelos más adecuados para manejar desequilibrios de clases, como modelos que asignen pesos diferentes a las clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-IV9noXGmRd"
   },
   "source": [
    "## 5. Informe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jdlH3Cg-GmRd"
   },
   "source": [
    "Elaboren un breve informe de lo realizado durante esta actividad práctica reseñando aspectos salientes, dificultades encontradas, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informe 📋\n",
    "\n",
    "##### Integrantes 👤\n",
    "> * Ezequiel Acosta\n",
    "> * Lis Alvarez\n",
    "> * Martin Moyano\n",
    "> * Sergio Garzón\n",
    "\n",
    "##### Aspectos sobresalientes/Conclusiones generales 🤔\n",
    "\n",
    ">Podemos observar que para ninguna de todas las técnicas aplicadas podemos mejorar una mejora en el rendimiento de los modelos, lo cual es una sorpresa ya que se tomo varios enfoques diferentes en los cuales se esperaba que contribuya a una mejor predicción. Una posible causa de esto puede llegar a ser lo que analizamos en el último punto, es decir, que un modelo dummy que siempre predice la presencia de sesgos, si efectivamente hay sesgos en nuestro experimento, no podemos mejorar el rendimiento del mismo. \n",
    "\n",
    "##### Dificultades encontradas 😕\n",
    "\n",
    ">Al momento de realizar el trabajo practico, nos encontramos con algunas dificultades que las detallamos a continuación:\n",
    "> \n",
    "> *  **Problemas en el One Hot Encoded:**: La principal pregunta fue si el OHE se realiza antes o después de la división del conjunto de datos en train y test. Luego se codificaron valores arbitrarios (0,1) a las columnas 'Validez_sil_%' y 'Creencia_sil_%', cuando se debería haber hecho para cada una de estas columnas otro OHE donde represente si es Validez_sil_%_V' o Validez_sil_%_I' toma valor 1 o 0. El problema con este enfoque, es que toda la columna toma el mismo valor, por lo que el OHE da como resultado una columna, en vez de dos. Para este tipo de codificación debería hacerce \"a mano\". \n",
    "> *  **Problemas con los resultados de las metricas calculadas:** No pudimos encontrar con ninguna de las pruebas ninguna mejora significativa de los scores de los modelos. \n",
    "\n",
    "##### Decisiones tomadas\n",
    "\n",
    "> * **Prueba de diferentes modelos:** Se probaron distintos modelos para ver si mejoraba el rendimiento \n",
    "> * **Optimización de Hiperparámetros:** Se realizaron procesos de optimización de hiperparámetros en los modelos para mejorar su capacidad de predicción.\n",
    "> * **Inclusión de otras características** Se incluyó la columna 'Modalida' para ver si mejoraba el rendimiento de los modelos. \n",
    "> * **Prueba de enfoque binario:** Se tomo un enfoque diferete donde convertimos el problema de regresión en uno de clasificación. \n",
    "\n",
    "##### Resultados obtenidos\n",
    "\n",
    "> Los resultados que obtuvimos fueron:\n",
    ">\n",
    ">Modelo Base vs. Mejor Modelo: El mejor modelo que logramos entrenar es el KNeighborsRegressor, obteniendo un MAE de 0.22017 y un WMAE de 0.19495, en contraste con los scores obtenidos con el modelo Dummy (MAE: 0.22543 y WMAE: 0.19532). Esta mejora, aunque aparentemente modesta, es significativa debido al rango de valores pequeños de nuestra variable objetivo.\n",
    ">\n",
    ">Codificación Ordinal vs. Codificación OHE: La decisión de utilizar una codificación ordinal para la variable 'ValidezxCreencia' no resultó óptima. Se recomienda considerar la aplicación de la codificación 'One-Hot Encoding' (OHE) para mejorar el modelo.\n",
    ">\n",
    ">Inclusión de la Variable 'Modalidad': La incorporación de la variable 'Modalidad' no condujo a mejoras significativas en el rendimiento del modelo. Se sugiere explorar otras estrategias de codificación o características para evaluar su impacto.\n",
    ">\n",
    ">Replanteamiento como Clasificación Binaria: Al replantear el problema como una clasificación binaria (presencia o ausencia de sesgos), notamos desafíos relacionados con el desequilibrio de clases y la necesidad de ajustar estrategias de clasificación para abordar este problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
